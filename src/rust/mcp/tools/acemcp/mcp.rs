use anyhow::Result;
use rmcp::model::{ErrorData as McpError, Tool, CallToolResult, Content};
use std::borrow::Cow;
use std::collections::{HashMap, HashSet};
use std::fs;
use std::io::Read;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Duration;

use reqwest::header::{AUTHORIZATION, CONTENT_TYPE};
use reqwest::Client;
use ring::digest::{Context as ShaContext, SHA256};
use ignore::gitignore::{Gitignore, GitignoreBuilder};
use serde::{Deserialize, Serialize};
use encoding_rs::{GBK, WINDOWS_1252, UTF_8};
use globset::{Glob, GlobSet, GlobSetBuilder};

use super::types::{
    AcemcpRequest,
    AcemcpConfig,
    ProjectIndexStatus,
    ProjectsIndexStatus,
    IndexStatus,
    ProjectFilesStatus,
    FileIndexStatus,
    FileIndexStatusKind,
    NestedProjectInfo,
    ProjectWithNestedStatus,
};
use crate::log_debug;
use crate::log_important;
// ä»£ç†æ¨¡å—ï¼ˆåœ¨ create_acemcp_client ä¸­ä½¿ç”¨ï¼‰

/// Acemcpå·¥å…·å®ç°
pub struct AcemcpTool;

impl AcemcpTool {
    /// æ‰§è¡Œä»£ç åº“æœç´¢ï¼ˆä»…æœç´¢ï¼Œä¸è§¦å‘ç´¢å¼•ï¼‰
    pub async fn search_context(request: AcemcpRequest) -> Result<CallToolResult, McpError> {
        log_important!(info,
            "Acemcpæœç´¢è¯·æ±‚ï¼ˆä»…æœç´¢æ¨¡å¼ï¼‰: project_root_path={}, query={}",
            request.project_root_path, request.query
        );

        // è¯»å–é…ç½®
        let mut acemcp_config = Self::get_acemcp_config()
            .await
            .map_err(|e| McpError::internal_error(format!("è·å–acemcpé…ç½®å¤±è´¥: {}", e), None))?;

        // è§„èŒƒåŒ– base_urlï¼ˆç¼ºåè®®æ—¶è¡¥ http://ï¼‰ï¼Œå¹¶å»é™¤æœ«å°¾æ–œæ 
        if let Some(base) = &acemcp_config.base_url {
            let normalized = normalize_base_url(base);
            acemcp_config.base_url = Some(normalized);
        }

        // é¦–æ¬¡æœç´¢æ—¶è‡ªåŠ¨å¯åŠ¨æ–‡ä»¶ç›‘å¬ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
        let watcher_manager = super::watcher::get_watcher_manager();
        if !watcher_manager.is_watching(&request.project_root_path) {
            log_debug!("é¦–æ¬¡æœç´¢ï¼Œå°è¯•å¯åŠ¨æ–‡ä»¶ç›‘å¬");
            if let Err(e) = watcher_manager.start_watching(
                request.project_root_path.clone(),
                acemcp_config.clone(),
                None  // ä½¿ç”¨é»˜è®¤é˜²æŠ–å»¶è¿Ÿ
            ).await {
                log_debug!("å¯åŠ¨æ–‡ä»¶ç›‘å¬å¤±è´¥ï¼ˆä¸å½±å“æœç´¢ï¼‰: {}", e);
            }
        }

        // 1. æ£€æŸ¥åˆå§‹ç´¢å¼•çŠ¶æ€
        let initial_state = get_initial_index_state(&request.project_root_path);
        log_debug!("é¡¹ç›®ç´¢å¼•çŠ¶æ€: {:?}", initial_state);

        // 2. æ ¹æ®çŠ¶æ€æ‰§è¡Œç›¸åº”æ“ä½œ
        let mut hint_message = String::new();
        match initial_state {
            InitialIndexState::Missing | InitialIndexState::Idle | InitialIndexState::Failed => {
                // å¯åŠ¨åå°ç´¢å¼•
                if let Err(e) = ensure_initial_index_background(&acemcp_config, &request.project_root_path).await {
                    log_debug!("å¯åŠ¨åå°ç´¢å¼•å¤±è´¥ï¼ˆä¸å½±å“æœç´¢ï¼‰: {}", e);
                } else {
                    hint_message = "\n\nğŸ’¡ æç¤ºï¼šå½“å‰é¡¹ç›®ç´¢å¼•å°šæœªå®Œå…¨åˆå§‹åŒ–ï¼Œå·²åœ¨åå°å¯åŠ¨ç´¢å¼•ï¼Œç¨åæœç´¢ç»“æœä¼šæ›´å®Œæ•´ã€‚".to_string();
                }
            }
            InitialIndexState::Indexing => {
                // æ­£åœ¨ç´¢å¼•ä¸­ï¼Œåº”ç”¨æ™ºèƒ½ç­‰å¾…
                if let Some((min_wait, max_wait)) = acemcp_config.smart_wait_range {
                    let wait_secs = fastrand::u64(min_wait..=max_wait);

                    log_important!(info, "æ£€æµ‹åˆ°ç´¢å¼•æ­£åœ¨è¿›è¡Œä¸­ï¼Œæ™ºèƒ½ç­‰å¾… {} ç§’åæ‰§è¡Œæœç´¢", wait_secs);
                    tokio::time::sleep(tokio::time::Duration::from_secs(wait_secs)).await;

                    hint_message = format!("\n\nğŸ’¡ æç¤ºï¼šæ£€æµ‹åˆ°ç´¢å¼•æ­£åœ¨è¿›è¡Œä¸­ï¼Œå·²ç­‰å¾… {} ç§’ä»¥è·å–æ›´å®Œæ•´çš„æœç´¢ç»“æœã€‚", wait_secs);
                }
            }
            InitialIndexState::Synced => {
                // å·²å®Œæˆç´¢å¼•ï¼Œç›´æ¥æœç´¢
                log_debug!("é¡¹ç›®ç´¢å¼•å·²å®Œæˆï¼Œç›´æ¥æ‰§è¡Œæœç´¢");
            }
        }

        // 3. æ‰§è¡Œæœç´¢ï¼ˆä¸è§¦å‘ç´¢å¼•ï¼‰
        let search_result = match search_only(&acemcp_config, &request.project_root_path, &request.query).await {
            Ok(text) => text,
            Err(e) => {
                return Ok(CallToolResult {
                    content: vec![Content::text(format!("Acemcpæœç´¢å¤±è´¥: {}", e))],
                    is_error: Some(true),
                    meta: None,
                    structured_content: None,
                });
            }
        };

        // 4. é™„åŠ æç¤ºä¿¡æ¯
        let final_result = if hint_message.is_empty() {
            search_result
        } else {
            format!("{}{}", search_result, hint_message)
        };

        Ok(CallToolResult { 
            content: vec![Content::text(final_result)], 
            is_error: None,
            meta: None,
            structured_content: None,
        })
    }

    /// æ‰§è¡Œç´¢å¼•æ›´æ–°ï¼ˆå‘åå…¼å®¹çš„ç´¢å¼•+æœç´¢ä¸€ä½“åŒ–æ¥å£ï¼‰
    pub async fn index_and_search_legacy(request: AcemcpRequest) -> Result<CallToolResult, McpError> {
        log_important!(info,
            "Acemcpç´¢å¼•+æœç´¢è¯·æ±‚ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰: project_root_path={}, query={}",
            request.project_root_path, request.query
        );

        // è¯»å–é…ç½®
        let mut acemcp_config = Self::get_acemcp_config()
            .await
            .map_err(|e| McpError::internal_error(format!("è·å–acemcpé…ç½®å¤±è´¥: {}", e), None))?;

        // è§„èŒƒåŒ– base_urlï¼ˆç¼ºåè®®æ—¶è¡¥ http://ï¼‰ï¼Œå¹¶å»é™¤æœ«å°¾æ–œæ 
        if let Some(base) = &acemcp_config.base_url {
            let normalized = normalize_base_url(base);
            acemcp_config.base_url = Some(normalized);
        }

        // å…ˆæ‰§è¡Œç´¢å¼•æ›´æ–°
        match update_index(&acemcp_config, &request.project_root_path).await {
            Ok(_blob_names) => {
                // ç´¢å¼•æˆåŠŸåæ‰§è¡Œæœç´¢
                match search_only(&acemcp_config, &request.project_root_path, &request.query).await {
                    Ok(text) => Ok(CallToolResult { 
                        content: vec![Content::text(text)], 
                        is_error: None,
                        meta: None,
                        structured_content: None,
                    }),
                    Err(e) => Ok(CallToolResult { 
                        content: vec![Content::text(format!("æœç´¢å¤±è´¥: {}", e))], 
                        is_error: Some(true),
                        meta: None,
                        structured_content: None,
                    })
                }
            }
            Err(e) => Ok(CallToolResult { 
                content: vec![Content::text(format!("ç´¢å¼•æ›´æ–°å¤±è´¥: {}", e))], 
                is_error: Some(true),
                meta: None,
                structured_content: None,
            })
        }
    }

    /// æ‰‹åŠ¨è§¦å‘ç´¢å¼•æ›´æ–°ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    /// æ”¯æŒçº§è”ç´¢å¼•åµŒå¥—çš„ Git å­é¡¹ç›®
    pub async fn trigger_index_update(project_root_path: String) -> Result<String> {
        log_important!(info, "æ‰‹åŠ¨è§¦å‘ç´¢å¼•æ›´æ–°: project_root_path={}", project_root_path);

        let acemcp_config = Self::get_acemcp_config().await?;
        
        // è¯»å–åµŒå¥—é¡¹ç›®ç´¢å¼•å¼€å…³ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        let index_nested = crate::config::load_standalone_config()
            .ok()
            .and_then(|c| c.mcp_config.acemcp_index_nested_projects)
            .unwrap_or(true);
        
        // æ£€æµ‹åµŒå¥—å­é¡¹ç›®
        let nested_status = match Self::get_project_with_nested_status(project_root_path.clone()) {
            Ok(status) => status,
            Err(e) => {
                log_debug!("è·å–åµŒå¥—é¡¹ç›®çŠ¶æ€å¤±è´¥ï¼Œå°†ç›´æ¥ç´¢å¼•çˆ¶ç›®å½•: {}", e);
                // å›é€€åˆ°åŸæœ‰é€»è¾‘
                return match update_index(&acemcp_config, &project_root_path).await {
                    Ok(blob_names) => Ok(format!("ç´¢å¼•æ›´æ–°æˆåŠŸï¼Œå…± {} ä¸ª blobs", blob_names.len())),
                    Err(e) => Err(anyhow::anyhow!("ç´¢å¼•æ›´æ–°å¤±è´¥: {}", e)),
                };
            }
        };
        
        let has_nested = !nested_status.nested_projects.is_empty();
        
        if has_nested && index_nested {
            // ç­–ç•¥A: æœ‰åµŒå¥—å­é¡¹ç›®ä¸”å¼€å…³å¯ç”¨ï¼Œåªç´¢å¼•å­é¡¹ç›®ï¼Œä¸ç´¢å¼•çˆ¶ç›®å½•ï¼ˆé¿å…æ— æ„ä¹‰ä¸Šä¼ ï¼‰
            log_important!(info, "æ£€æµ‹åˆ° {} ä¸ªåµŒå¥— Git å­é¡¹ç›®ï¼Œå°†åˆ†åˆ«ç´¢å¼•", nested_status.nested_projects.len());
            
            let mut results = Vec::new();
            let mut errors = Vec::new();
            
            for nested in &nested_status.nested_projects {
                log_important!(info, "ç´¢å¼•åµŒå¥—å­é¡¹ç›®: {}", nested.absolute_path);
                match update_index(&acemcp_config, &nested.absolute_path).await {
                    Ok(blobs) => {
                        log_important!(info, "å­é¡¹ç›®ç´¢å¼•æˆåŠŸ: {} ({} blobs)", nested.relative_path, blobs.len());
                        results.push((nested.relative_path.clone(), blobs.len()));
                    }
                    Err(e) => {
                        log_important!(info, "å­é¡¹ç›®ç´¢å¼•å¤±è´¥: {} - {}", nested.relative_path, e);
                        errors.push((nested.relative_path.clone(), e.to_string()));
                    }
                }
            }
            
            if errors.is_empty() {
                Ok(format!(
                    "ç´¢å¼•æ›´æ–°æˆåŠŸï¼Œå…± {} ä¸ªå­é¡¹ç›®: {:?}",
                    results.len(),
                    results
                ))
            } else {
                Ok(format!(
                    "ç´¢å¼•æ›´æ–°éƒ¨åˆ†æˆåŠŸ: æˆåŠŸ {} ä¸ªï¼Œå¤±è´¥ {} ä¸ªã€‚æˆåŠŸ: {:?}ï¼Œå¤±è´¥: {:?}",
                    results.len(),
                    errors.len(),
                    results,
                    errors
                ))
            }
        } else {
            // ç­–ç•¥B: æ— åµŒå¥—å­é¡¹ç›®æˆ–å¼€å…³å…³é—­ï¼Œç›´æ¥ç´¢å¼•
            match update_index(&acemcp_config, &project_root_path).await {
                Ok(blob_names) => Ok(format!("ç´¢å¼•æ›´æ–°æˆåŠŸï¼Œå…± {} ä¸ª blobs", blob_names.len())),
                Err(e) => Err(anyhow::anyhow!("ç´¢å¼•æ›´æ–°å¤±è´¥: {}", e)),
            }
        }
    }

    /// è·å–é¡¹ç›®ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub fn get_index_status(project_root_path: String) -> ProjectIndexStatus {
        get_project_status(&project_root_path)
    }

    /// è·å–æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub fn get_all_index_status() -> ProjectsIndexStatus {
        load_projects_status()
    }

    /// è·å–é¡¹ç›®å†…æ‰€æœ‰å¯ç´¢å¼•æ–‡ä»¶çš„ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    pub async fn get_project_files_status(project_root_path: String) -> anyhow::Result<ProjectFilesStatus> {
        // è¯»å– Acemcp é…ç½®ï¼Œä¸»è¦ç”¨äºè·å–æ‰©å±•åã€æ’é™¤è§„åˆ™å’Œåˆ†å—è¡Œæ•°
        let acemcp_config = Self::get_acemcp_config().await?;
        let max_lines = acemcp_config.max_lines_per_blob.unwrap_or(800) as usize;
        let text_exts = acemcp_config.text_extensions.clone().unwrap_or_default();
        let exclude_patterns = acemcp_config.exclude_patterns.clone().unwrap_or_default();

        // è¯»å– projects.jsonï¼Œè·å–å·²ç´¢å¼•çš„ blob åç§°é›†åˆ
        let projects_path = home_projects_file();
        let projects: ProjectsFile = if projects_path.exists() {
            let data = fs::read_to_string(&projects_path).unwrap_or_default();
            serde_json::from_str(&data).unwrap_or_default()
        } else {
            ProjectsFile::default()
        };

        // ä½¿ç”¨ normalize_project_path å»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€
        let normalized_root = normalize_project_path(
            &PathBuf::from(&project_root_path)
                .canonicalize()
                .unwrap_or_else(|_| PathBuf::from(&project_root_path))
                .to_string_lossy()
        );

        let existing_blob_names: std::collections::HashSet<String> = projects
            .0
            .get(&normalized_root)
            .cloned()
            .unwrap_or_default()
            .into_iter()
            .collect();

        let files = collect_file_statuses(
            &project_root_path,
            &text_exts,
            &exclude_patterns,
            max_lines,
            &existing_blob_names,
        )?;

        Ok(ProjectFilesStatus {
            project_root: normalized_root,
            files,
        })
    }

    /// è·å–acemcpé…ç½®ï¼ˆå…¬æœ‰æ–¹æ³•ï¼Œä¾› commands æ¨¡å—è°ƒç”¨ï¼‰
    pub async fn get_acemcp_config() -> Result<AcemcpConfig> {
        // ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–acemcpé…ç½®
        let config = crate::config::load_standalone_config()
            .map_err(|e| anyhow::anyhow!("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {}", e))?;

        Ok(AcemcpConfig {
            base_url: config.mcp_config.acemcp_base_url,
            token: config.mcp_config.acemcp_token,
            batch_size: config.mcp_config.acemcp_batch_size,
            max_lines_per_blob: config.mcp_config.acemcp_max_lines_per_blob,
            text_extensions: config.mcp_config.acemcp_text_extensions,
            exclude_patterns: config.mcp_config.acemcp_exclude_patterns,
            // æ™ºèƒ½ç­‰å¾…é»˜è®¤å€¼ï¼š1-5 ç§’éšæœºç­‰å¾…
            smart_wait_range: Some((1, 5)),
            // ä»£ç†é…ç½®
            proxy_enabled: config.mcp_config.acemcp_proxy_enabled,
            proxy_host: config.mcp_config.acemcp_proxy_host,
            proxy_port: config.mcp_config.acemcp_proxy_port,
            proxy_type: config.mcp_config.acemcp_proxy_type,
            proxy_username: config.mcp_config.acemcp_proxy_username,
            proxy_password: config.mcp_config.acemcp_proxy_password,
        })
    }


    /// è·å–å·¥å…·å®šä¹‰
    pub fn get_tool_definition() -> Tool {
        let schema = serde_json::json!({
            "type": "object",
            "properties": {
                "project_root_path": {
                    "type": "string",
                    "description": "é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œä½¿ç”¨æ­£æ–œæ (/)ä½œä¸ºåˆ†éš”ç¬¦ã€‚ä¾‹å¦‚ï¼šC:/Users/username/projects/myproject"
                },
                "query": {
                    "type": "string",
                    "description": "ç”¨äºæŸ¥æ‰¾ç›¸å…³ä»£ç ä¸Šä¸‹æ–‡çš„è‡ªç„¶è¯­è¨€æœç´¢æŸ¥è¯¢ã€‚æ­¤å·¥å…·æ‰§è¡Œè¯­ä¹‰æœç´¢å¹¶è¿”å›ä¸æŸ¥è¯¢åŒ¹é…çš„ä»£ç ç‰‡æ®µã€‚ä¾‹å¦‚ï¼š'æ—¥å¿—é…ç½®è®¾ç½®åˆå§‹åŒ–logger'ï¼ˆæŸ¥æ‰¾æ—¥å¿—è®¾ç½®ä»£ç ï¼‰ã€'ç”¨æˆ·è®¤è¯ç™»å½•'ï¼ˆæŸ¥æ‰¾è®¤è¯ç›¸å…³ä»£ç ï¼‰ã€'æ•°æ®åº“è¿æ¥æ± 'ï¼ˆæŸ¥æ‰¾æ•°æ®åº“è¿æ¥ä»£ç ï¼‰ã€'é”™è¯¯å¤„ç†å¼‚å¸¸'ï¼ˆæŸ¥æ‰¾é”™è¯¯å¤„ç†æ¨¡å¼ï¼‰ã€'APIç«¯ç‚¹è·¯ç”±'ï¼ˆæŸ¥æ‰¾APIè·¯ç”±å®šä¹‰ï¼‰ã€‚å·¥å…·è¿”å›å¸¦æœ‰æ–‡ä»¶è·¯å¾„å’Œè¡Œå·çš„æ ¼å¼åŒ–æ–‡æœ¬ç‰‡æ®µï¼Œæ˜¾ç¤ºç›¸å…³ä»£ç çš„ä½ç½®ã€‚"
                }
            },
            "required": ["project_root_path", "query"]
        });

        if let serde_json::Value::Object(schema_map) = schema {
            Tool {
                name: Cow::Borrowed("sou"),
                description: Some(Cow::Borrowed("åŸºäºæŸ¥è¯¢åœ¨ç‰¹å®šé¡¹ç›®ä¸­æœç´¢ç›¸å…³çš„ä»£ç ä¸Šä¸‹æ–‡ã€‚ä¾èµ–åå°å¢é‡ç´¢å¼•ä¸æ–‡ä»¶ç›‘å¬æœºåˆ¶ç»´æŠ¤ç´¢å¼•ï¼Œå¹¶åœ¨ç´¢å¼•è¿›è¡Œä¸­é€šè¿‡æ™ºèƒ½ç­‰å¾…åœ¨å®æ—¶æ€§å’Œå“åº”é€Ÿåº¦ä¹‹é—´åšå¹³è¡¡ã€‚è¿”å›ä»£ç åº“ä¸­ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸å…³çš„æ ¼å¼åŒ–æ–‡æœ¬ç‰‡æ®µã€‚")),
                input_schema: Arc::new(schema_map),
                annotations: None,
                icons: None,
                meta: None,
                output_schema: None,
                title: None,
            }
        } else {
            panic!("Schema creation failed");
        }
    }

    /// è·å–é¡¹ç›®åŠå…¶åµŒå¥—å­é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ï¼ˆä¾› Tauri å‘½ä»¤è°ƒç”¨ï¼‰
    /// 
    /// è¯¥æ–¹æ³•ä¼šæ‰«æé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ç›´æ¥å­ç›®å½•ï¼Œæ£€æµ‹å“ªäº›æ˜¯ç‹¬ç«‹çš„ Git ä»“åº“ï¼Œ
    /// å¹¶è¿”å›æ¯ä¸ªå­é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ã€‚ç”¨äºå‰ç«¯å±•ç¤ºå¤šé¡¹ç›®ç»“æ„ã€‚
    pub fn get_project_with_nested_status(project_root_path: String) -> Result<ProjectWithNestedStatus> {
        let root_path = PathBuf::from(&project_root_path);
        // å…³é”®æ ¡éªŒï¼šè·¯å¾„ä¸å­˜åœ¨æ—¶ç›´æ¥è¿”å›é”™è¯¯ï¼Œé¿å…å‰ç«¯é™é»˜å¤±è´¥
        if !root_path.exists() || !root_path.is_dir() {
            anyhow::bail!("é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: {}", project_root_path);
        }
        let root_status = get_project_status(&project_root_path);
        
        let mut nested_projects = Vec::new();
        let mut regular_directories = Vec::new();

        // ä»é…ç½®è¯»å–æ’é™¤æ¨¡å¼ï¼Œç”¨äºè¿‡æ»¤åµŒå¥—ç›®å½•ï¼ˆä¸ç´¢å¼•é˜¶æ®µä¿æŒä¸€è‡´ï¼‰
        let exclude_patterns = crate::config::load_standalone_config()
            .ok()
            .and_then(|c| c.mcp_config.acemcp_exclude_patterns)
            .unwrap_or_else(|| {
                vec![
                    "node_modules".to_string(),
                    ".git".to_string(),
                    "target".to_string(),
                    "dist".to_string(),
                ]
            });
        let exclude_globset = if exclude_patterns.is_empty() {
            None
        } else {
            match build_exclude_globset(&exclude_patterns) {
                Ok(gs) => Some(gs),
                Err(e) => {
                    log_debug!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥ï¼Œå°†å¿½ç•¥ç›®å½•è¿‡æ»¤: {}", e);
                    None
                }
            }
        };
        
        // æ‰«æç›´æ¥å­ç›®å½•ï¼ˆä»…ç¬¬ä¸€å±‚ï¼‰
        let entries = fs::read_dir(&root_path)
            .map_err(|e| anyhow::anyhow!("è¯»å–é¡¹ç›®æ ¹ç›®å½•å¤±è´¥: {}", e))?;
        for entry in entries {
            let entry = entry.map_err(|e| anyhow::anyhow!("è¯»å–ç›®å½•æ¡ç›®å¤±è´¥: {}", e))?;
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            
            let dir_name = path.file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("")
                .to_string();
            
            // è·³è¿‡éšè—ç›®å½•
            if dir_name.starts_with('.') {
                continue;
            }
            // ä½¿ç”¨é…ç½®æ’é™¤ç›®å½•/è·¯å¾„ï¼ˆæ”¯æŒ globï¼‰
            if should_exclude(&path, &root_path, exclude_globset.as_ref()) {
                continue;
            }
            
            // æ£€æµ‹æ˜¯å¦æ˜¯ Git ä»“åº“
            let git_dir = path.join(".git");
            let is_git_repo = git_dir.exists() && git_dir.is_dir();
            
            if is_git_repo {
                // è·å–å­é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
                let sub_path_str = normalize_project_path(&path.to_string_lossy());
                let sub_status = get_project_status(&sub_path_str);
                
                // ç²—ç•¥ä¼°è®¡æ–‡ä»¶æ•°é‡ï¼ˆä½¿ç”¨ç´¢å¼•çŠ¶æ€ä¸­çš„ total_filesï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ä¸º 0ï¼‰
                let file_count = if sub_status.status != IndexStatus::Idle {
                    sub_status.total_files
                } else {
                    0
                };
                
                nested_projects.push(NestedProjectInfo {
                    relative_path: dir_name,
                    absolute_path: sub_path_str,
                    is_git_repo: true,
                    index_status: Some(sub_status),
                    file_count,
                });
            } else {
                regular_directories.push(dir_name);
            }
        }
        
        // æŒ‰å­—æ¯é¡ºåºæ’åº
        nested_projects.sort_by(|a, b| a.relative_path.cmp(&b.relative_path));
        regular_directories.sort();
        
        Ok(ProjectWithNestedStatus {
            root_status,
            nested_projects,
            regular_directories,
        })
    }
}

// ---------------- å·²ç§»é™¤ Python Web æœåŠ¡ä¾èµ–ï¼Œå®Œå…¨ä½¿ç”¨ Rust å®ç° ----------------

// ---------------- ç´¢å¼•åˆå§‹åŒ–çŠ¶æ€æšä¸¾ ----------------

/// ç´¢å¼•åˆå§‹åŒ–çŠ¶æ€
#[derive(Debug, Clone, PartialEq)]
pub enum InitialIndexState {
    /// é¡¹ç›®è®°å½•ä¸å­˜åœ¨
    Missing,
    /// ä»æœªç´¢å¼•è¿‡ï¼ˆçŠ¶æ€ä¸º Idle ä¸” total_files == 0ï¼‰
    Idle,
    /// å·²å®Œæˆç´¢å¼•
    Synced,
    /// æ­£åœ¨ç´¢å¼•ä¸­
    Indexing,
    /// ä¸Šæ¬¡ç´¢å¼•å¤±è´¥
    Failed,
}

/// è·å–é¡¹ç›®çš„åˆå§‹ç´¢å¼•çŠ¶æ€
pub fn get_initial_index_state(project_root: &str) -> InitialIndexState {
    let status = get_project_status(project_root);

    match status.status {
        IndexStatus::Idle if status.total_files == 0 => InitialIndexState::Idle,
        IndexStatus::Idle => InitialIndexState::Missing,
        IndexStatus::Synced => InitialIndexState::Synced,
        IndexStatus::Indexing => InitialIndexState::Indexing,
        IndexStatus::Failed => InitialIndexState::Failed,
    }
}

/// ç¡®ä¿åå°ç´¢å¼•å·²å¯åŠ¨ï¼ˆéé˜»å¡ï¼‰
/// ä»…åœ¨é¡¹ç›®æœªåˆå§‹åŒ–æˆ–ç´¢å¼•å¤±è´¥æ—¶å¯åŠ¨åå°ç´¢å¼•ä»»åŠ¡
pub async fn ensure_initial_index_background(config: &AcemcpConfig, project_root: &str) -> anyhow::Result<()> {
    let state = get_initial_index_state(project_root);

    match state {
        InitialIndexState::Missing | InitialIndexState::Idle | InitialIndexState::Failed => {
            // åœ¨åå°å¯åŠ¨ç´¢å¼•ä»»åŠ¡
            let config_clone = config.clone();
            let project_root_clone = project_root.to_string();

            tokio::spawn(async move {
                log_important!(info, "åå°ç´¢å¼•ä»»åŠ¡å¯åŠ¨: project_root={}", project_root_clone);
                if let Err(e) = update_index(&config_clone, &project_root_clone).await {
                    log_important!(info, "åå°ç´¢å¼•å¤±è´¥: project_root={}, error={}", project_root_clone, e);
                } else {
                    log_important!(info, "åå°ç´¢å¼•æˆåŠŸ: project_root={}", project_root_clone);
                }
            });

            Ok(())
        }
        InitialIndexState::Synced | InitialIndexState::Indexing => {
            // å·²ç»å®Œæˆæˆ–æ­£åœ¨è¿›è¡Œï¼Œæ— éœ€æ“ä½œ
            Ok(())
        }
    }
}

// ---------------- æ•´åˆ temp é€»è¾‘ï¼šç´¢å¼•ã€ä¸Šä¼ ã€æ£€ç´¢ ----------------

#[derive(Serialize, Deserialize, Clone)]
struct BlobItem {
    path: String,
    content: String,
}

#[derive(Serialize, Deserialize, Default)]
pub(crate) struct ProjectsFile(pub HashMap<String, Vec<String>>);

fn normalize_base_url(input: &str) -> String {
    let mut url = input.trim().to_string();
    if !(url.starts_with("http://") || url.starts_with("https://")) {
        url = format!("http://{}", url);
    }
    while url.ends_with('/') { url.pop(); }
    url
}

/// è§„èŒƒåŒ–é¡¹ç›®è·¯å¾„ï¼Œå»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€å¹¶ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
/// 
/// Windows çš„ `canonicalize()` ä¼šè¿”å› `//?/C:/...` æˆ– `\\?\C:\...` æ ¼å¼çš„è·¯å¾„ï¼Œ
/// è¿™ä¼šå¯¼è‡´å‰åç«¯è·¯å¾„åŒ¹é…å¤±è´¥ã€‚æ­¤å‡½æ•°ç¡®ä¿è·¯å¾„æ ¼å¼ç»Ÿä¸€ã€‚
fn normalize_project_path(path: &str) -> String {
    let mut p = path.to_string();
    
    // å¤„ç† //?/ æ ¼å¼ï¼ˆcanonicalize åœ¨æŸäº›æƒ…å†µä¸‹è¿”å›ï¼‰
    if p.starts_with("//?/") {
        p = p[4..].to_string();
    }
    // å¤„ç† \\?\ æ ¼å¼ï¼ˆWindows æ‰©å±•è·¯å¾„è¯­æ³•ï¼‰
    else if p.starts_with("\\\\?\\") {
        p = p[4..].to_string();
    }
    
    // ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
    p.replace('\\', "/")
}

async fn retry_request<F, Fut, T>(mut f: F, max_retries: usize, base_delay_secs: f64) -> anyhow::Result<T>
where
    F: FnMut() -> Fut,
    Fut: std::future::Future<Output = anyhow::Result<T>>,
{
    let mut attempt = 0usize;
    let mut last_error_str: Option<String> = None;
    
    while attempt < max_retries {
        match f().await {
            Ok(v) => {
                if attempt > 0 {
                    log_debug!("è¯·æ±‚åœ¨ç¬¬{}æ¬¡å°è¯•åæˆåŠŸ", attempt + 1);
                }
                return Ok(v);
            }
            Err(e) => {
                last_error_str = Some(e.to_string());
                attempt += 1;
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
                let error_str = e.to_string();
                let is_retryable = error_str.contains("timeout") 
                    || error_str.contains("connection") 
                    || error_str.contains("network")
                    || error_str.contains("temporary");
                
                if attempt >= max_retries || !is_retryable {
                    log_debug!("è¯·æ±‚å¤±è´¥ï¼Œä¸å†é‡è¯•: {}", e);
                    return Err(e);
                }
                
                let delay = base_delay_secs * 2f64.powi((attempt as i32) - 1);
                let ms = (delay * 1000.0) as u64;
                log_debug!("è¯·æ±‚å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•({}/{}), ç­‰å¾… {}ms: {}", attempt, max_retries, ms, e);
                tokio::time::sleep(Duration::from_millis(ms)).await;
            }
        }
    }
    
    Err(last_error_str
        .and_then(|s| anyhow::anyhow!(s).into())
        .unwrap_or_else(|| anyhow::anyhow!("æœªçŸ¥é”™è¯¯")))
}

pub(crate) fn home_projects_file() -> PathBuf {
    let home = dirs::home_dir().unwrap_or_else(|| PathBuf::from("."));
    let data_dir = home.join(".acemcp").join("data");
    let _ = fs::create_dir_all(&data_dir);
    data_dir.join("projects.json")
}

/// è·å–é¡¹ç›®ç´¢å¼•çŠ¶æ€æ–‡ä»¶è·¯å¾„
fn home_projects_status_file() -> PathBuf {
    let home = dirs::home_dir().unwrap_or_else(|| PathBuf::from("."));
    let data_dir = home.join(".acemcp").join("data");
    let _ = fs::create_dir_all(&data_dir);
    data_dir.join("projects_status.json")
}

/// è¯»å–æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn load_projects_status() -> ProjectsIndexStatus {
    let status_path = home_projects_status_file();
    log_debug!("ğŸ“‚ [load_projects_status] çŠ¶æ€æ–‡ä»¶è·¯å¾„: {:?}", status_path);
    
    if status_path.exists() {
        let data = fs::read_to_string(&status_path).unwrap_or_default();
        log_debug!("ğŸ“„ [load_projects_status] è¯»å–åˆ°çŠ¶æ€æ–‡ä»¶ï¼Œå¤§å°: {} å­—èŠ‚", data.len());
        
        match serde_json::from_str::<ProjectsIndexStatus>(&data) {
            Ok(status) => {
                log_debug!("âœ… [load_projects_status] è§£ææˆåŠŸï¼Œé¡¹ç›®æ•°: {}", status.projects.len());
                status
            }
            Err(e) => {
                log_debug!("âš ï¸ [load_projects_status] è§£æå¤±è´¥: {}", e);
                ProjectsIndexStatus::default()
            }
        }
    } else {
        log_debug!("ğŸ“­ [load_projects_status] çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨");
        ProjectsIndexStatus::default()
    }
}

/// ä¿å­˜æ‰€æœ‰é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn save_projects_status(status: &ProjectsIndexStatus) -> Result<()> {
    let status_path = home_projects_status_file();
    let data = serde_json::to_string_pretty(status)?;
    fs::write(status_path, data)?;
    Ok(())
}

/// æ›´æ–°æŒ‡å®šé¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn update_project_status<F>(project_root: &str, updater: F) -> Result<()>
where
    F: FnOnce(&mut ProjectIndexStatus),
{
    let mut all_status = load_projects_status();
    // ä½¿ç”¨ normalize_project_path å»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€
    let normalized_root = normalize_project_path(
        &PathBuf::from(project_root)
            .canonicalize()
            .unwrap_or_else(|_| PathBuf::from(project_root))
            .to_string_lossy()
    );

    let project_status = all_status.projects
        .entry(normalized_root.clone())
        .or_insert_with(|| {
            let mut status = ProjectIndexStatus::default();
            status.project_root = normalized_root;
            status
        });

    updater(project_status);
    save_projects_status(&all_status)?;
    Ok(())
}

/// è·å–æŒ‡å®šé¡¹ç›®çš„ç´¢å¼•çŠ¶æ€
fn get_project_status(project_root: &str) -> ProjectIndexStatus {
    let all_status = load_projects_status();
    // ä½¿ç”¨ normalize_project_path å»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€
    let normalized_root = normalize_project_path(
        &PathBuf::from(project_root)
            .canonicalize()
            .unwrap_or_else(|_| PathBuf::from(project_root))
            .to_string_lossy()
    );

    all_status.projects.get(&normalized_root).cloned().unwrap_or_else(|| {
        let mut status = ProjectIndexStatus::default();
        status.project_root = normalized_root;
        status
    })
}

/// è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§ç¼–ç æ£€æµ‹
/// å°è¯•çš„ç¼–ç é¡ºåºï¼šutf-8, gbk (åŒ…å« gb2312), windows-1252 (åŒ…å« latin-1)
/// å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ™ä½¿ç”¨ utf-8 with errors='ignore'
fn read_file_with_encoding(path: &Path) -> Option<String> {
    let mut file = fs::File::open(path).ok()?;
    let mut buf = Vec::new();
    if file.read_to_end(&mut buf).is_err() {
        return None;
    }

    // å°è¯• utf-8
    let (decoded, _, had_errors) = UTF_8.decode(&buf);
    if !had_errors {
        return Some(decoded.into_owned());
    }

    // å°è¯• gbk
    let (decoded, _, had_errors) = GBK.decode(&buf);
    if !had_errors {
        log_debug!("æˆåŠŸä½¿ç”¨ GBK ç¼–ç è¯»å–æ–‡ä»¶: {:?}", path);
        return Some(decoded.into_owned());
    }

    // å°è¯• gb2312 (GBK æ˜¯ GB2312 çš„è¶…é›†ï¼Œå¯ä»¥å¤„ç† GB2312 ç¼–ç )
    // encoding_rs ä¸­æ²¡æœ‰å•ç‹¬çš„ GB2312ï¼Œä½¿ç”¨ GBK ä»£æ›¿
    // GBK å·²ç»åœ¨ä¸Šä¸€æ­¥å°è¯•è¿‡äº†ï¼Œè¿™é‡Œè·³è¿‡

    // å°è¯• latin-1 (WINDOWS_1252 æ˜¯ ISO-8859-1 çš„è¶…é›†ï¼Œå¯ä»¥å¤„ç†å¤§éƒ¨åˆ† latin-1 ç¼–ç )
    let (decoded, _, had_errors) = WINDOWS_1252.decode(&buf);
    if !had_errors {
        log_debug!("æˆåŠŸä½¿ç”¨ WINDOWS_1252 ç¼–ç è¯»å–æ–‡ä»¶: {:?}", path);
        return Some(decoded.into_owned());
    }

    // å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨ utf-8 with errors='ignore' (lossy è§£ç )
    let (decoded, _, _) = UTF_8.decode(&buf);
    log_debug!("ä½¿ç”¨ UTF-8 (lossy) è¯»å–æ–‡ä»¶ï¼Œéƒ¨åˆ†å­—ç¬¦å¯èƒ½ä¸¢å¤±: {:?}", path);
    Some(decoded.into_owned())
}

fn sha256_hex(path: &str, content: &str) -> String {
    let mut ctx = ShaContext::new(&SHA256);
    // å…ˆæ›´æ–°è·¯å¾„çš„å“ˆå¸Œï¼Œå†æ›´æ–°å†…å®¹çš„å“ˆå¸Œï¼Œä¸Pythonç‰ˆæœ¬ä¿æŒä¸€è‡´
    ctx.update(path.as_bytes());
    ctx.update(content.as_bytes());
    let digest = ctx.finish();
    hex::encode(digest.as_ref())
}

/// åˆ†å‰²æ–‡ä»¶å†…å®¹ä¸ºå¤šä¸ª blobï¼ˆå¦‚æœè¶…è¿‡æœ€å¤§è¡Œæ•°ï¼‰
/// ä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šchunk ç´¢å¼•ä» 1 å¼€å§‹
fn split_content(path: &str, content: &str, max_lines: usize) -> Vec<BlobItem> {
    let lines: Vec<&str> = content.split_inclusive('\n').collect();
    let total_lines = lines.len();
    
    // å¦‚æœæ–‡ä»¶åœ¨é™åˆ¶å†…ï¼Œè¿”å›å•ä¸ª blob
    if total_lines <= max_lines {
        return vec![BlobItem { path: path.to_string(), content: content.to_string() }];
    }

    // è®¡ç®—éœ€è¦çš„ chunk æ•°é‡
    let num_chunks = (total_lines + max_lines - 1) / max_lines;
    let mut blobs = Vec::new();

    // æŒ‰ chunk ç´¢å¼•åˆ†å‰²ï¼ˆä» 0 å¼€å§‹ï¼Œä½†æ˜¾ç¤ºæ—¶ä» 1 å¼€å§‹ï¼‰
    for chunk_idx in 0..num_chunks {
        let start_line = chunk_idx * max_lines;
        let end_line = usize::min(start_line + max_lines, total_lines);
        let chunk_lines = &lines[start_line..end_line];
        let chunk_content = chunk_lines.join("");

        // chunk ç¼–å·ä» 1 å¼€å§‹ï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        let chunk_path = format!("{}#chunk{}of{}", path, chunk_idx + 1, num_chunks);
        blobs.push(BlobItem { path: chunk_path, content: chunk_content });
    }

    blobs
}

// å»é™¤ blob è·¯å¾„ä¸­çš„ chunk åç¼€ï¼Œæ¢å¤æ–‡ä»¶çº§è·¯å¾„
fn strip_chunk_suffix(path: &str) -> &str {
    path.split("#chunk").next().unwrap_or(path)
}

/// æ„å»ºæ’é™¤æ¨¡å¼çš„ GlobSet
fn build_exclude_globset(exclude_patterns: &[String]) -> Result<GlobSet> {
    let mut builder = GlobSetBuilder::new();
    for pattern in exclude_patterns {
        // å°è¯•å°†æ¨¡å¼è½¬æ¢ä¸º Glob
        if let Ok(glob) = Glob::new(pattern) {
            builder.add(glob);
        } else {
            log_debug!("æ— æ•ˆçš„æ’é™¤æ¨¡å¼ï¼Œè·³è¿‡: {}", pattern);
        }
    }
    builder.build().map_err(|e| anyhow::anyhow!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥: {}", e))
}

/// æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤
/// ä½¿ç”¨ globset è¿›è¡Œå®Œæ•´çš„ fnmatch æ¨¡å¼åŒ¹é…ï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
/// Python ç‰ˆæœ¬ä½¿ç”¨ fnmatch.fnmatch æ£€æŸ¥è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†å’Œå®Œæ•´è·¯å¾„
fn should_exclude(path: &Path, root: &Path, exclude_globset: Option<&GlobSet>) -> bool {
    if exclude_globset.is_none() {
        return false;
    }
    let globset = exclude_globset.unwrap();

    // è·å–ç›¸å¯¹è·¯å¾„
    let rel = match path.strip_prefix(root) {
        Ok(rel) => rel,
        Err(_) => path,
    };

    // è½¬æ¢ä¸ºä½¿ç”¨æ­£æ–œæ çš„å­—ç¬¦ä¸²ï¼ˆç”¨äºåŒ¹é…ï¼‰
    let rel_forward = rel.to_string_lossy().replace('\\', "/");
    
    // æ£€æŸ¥å®Œæ•´ç›¸å¯¹è·¯å¾„ï¼ˆä¸ Python ç‰ˆæœ¬çš„ fnmatch(path_str, pattern) ä¸€è‡´ï¼‰
    if globset.is_match(&rel_forward) {
        return true;
    }

    // æ£€æŸ¥è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†ï¼ˆä¸ Python ç‰ˆæœ¬çš„ fnmatch(part, pattern) ä¸€è‡´ï¼‰
    for part in rel.iter() {
        if let Some(part_str) = part.to_str() {
            if globset.is_match(part_str) {
                return true;
            }
        }
    }

    false
}

fn build_gitignore(root: &Path) -> Option<Gitignore> {
    let mut builder = GitignoreBuilder::new(root);
    let gi_path = root.join(".gitignore");
    if gi_path.exists() {
        if builder.add(gi_path).is_some() { return None; }
        return match builder.build() { Ok(gi) => Some(gi), Err(_) => None };
    }
    None
}

fn collect_blobs(root: &str, text_exts: &[String], exclude_patterns: &[String], max_lines_per_blob: usize) -> anyhow::Result<Vec<BlobItem>> {
    let root_path = PathBuf::from(root);
    if !root_path.exists() { anyhow::bail!("é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: {}", root); }
    
    log_important!(info, "å¼€å§‹æ”¶é›†ä»£ç æ–‡ä»¶: æ ¹ç›®å½•={}, æ‰©å±•å={:?}, æ’é™¤æ¨¡å¼={:?}", root, text_exts, exclude_patterns);
    
    // æ„å»ºæ’é™¤æ¨¡å¼çš„ GlobSet
    let exclude_globset = if exclude_patterns.is_empty() {
        None
    } else {
        match build_exclude_globset(exclude_patterns) {
            Ok(gs) => Some(gs),
            Err(e) => {
                log_debug!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•åŒ¹é…: {}", e);
                None
            }
        }
    };
    
    let mut out = Vec::new();
    let gitignore = build_gitignore(&root_path);
    let mut dirs_stack = vec![root_path.clone()];
    let mut scanned_files = 0;
    let mut indexed_files = 0;
    let mut excluded_count = 0;
    
    while let Some(dir) = dirs_stack.pop() {
        let entries = match fs::read_dir(&dir) { Ok(e) => e, Err(_) => continue };
        for entry in entries.flatten() {
            let p = entry.path();
            
            // æ£€æŸ¥ .gitignore
            if let Some(gi) = &gitignore {
                if gi.matched_path_or_any_parents(&p, p.is_dir()).is_ignore() { continue; }
            }
            
            // æ£€æŸ¥æ’é™¤æ¨¡å¼
            if p.is_dir() {
                if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                    excluded_count += 1;
                    continue;
                }
                dirs_stack.push(p);
                continue;
            }
            
            scanned_files += 1;
            if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                excluded_count += 1;
                log_debug!("æ’é™¤æ–‡ä»¶: {:?}", p);
                continue;
            }
            
            // æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            let ext_ok = p.extension().and_then(|s| s.to_str()).map(|e| {
                let dot = format!(".{}", e).to_lowercase();
                text_exts.iter().any(|te| te.eq_ignore_ascii_case(&dot))
            }).unwrap_or(false);
            if !ext_ok { continue; }
            
            // è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨å¤šç¼–ç æ”¯æŒï¼‰
            let rel = p.strip_prefix(&root_path).unwrap_or(&p).to_string_lossy().replace('\\', "/");
            if let Some(content) = read_file_with_encoding(&p) {
                let parts = split_content(&rel, &content, max_lines_per_blob);
                let blob_count = parts.len();
                indexed_files += 1;
                out.extend(parts);
                log_important!(info, "ç´¢å¼•æ–‡ä»¶: path={}, content_length={}, blobs={}", rel, content.len(), blob_count);
            } else {
                log_debug!("æ— æ³•è¯»å–æ–‡ä»¶: {:?}", p);
            }
        }
    }
    
    log_important!(info, "æ–‡ä»¶æ”¶é›†å®Œæˆ: æ‰«ææ–‡ä»¶æ•°={}, ç´¢å¼•æ–‡ä»¶æ•°={}, ç”Ÿæˆblobsæ•°={}, æ’é™¤æ–‡ä»¶/ç›®å½•æ•°={}", scanned_files, indexed_files, out.len(), excluded_count);
    Ok(out)
}

/// æ”¶é›†é¡¹ç›®å†…æ‰€æœ‰å¯ç´¢å¼•æ–‡ä»¶çš„ç´¢å¼•çŠ¶æ€
///
/// ä¸ºé¿å…å¼•å…¥æ–°çš„æŒä¹…åŒ–ç»“æ„ï¼Œè¿™é‡Œé€šè¿‡é‡æ–°æ‰«ææ–‡ä»¶å¹¶å¤ç”¨ä¸ç´¢å¼•é˜¶æ®µç›¸åŒçš„
/// è·¯å¾„è§„èŒƒåŒ–ä¸åˆ†å—é€»è¾‘ï¼ŒåŸºäºç°æœ‰çš„ blob å“ˆå¸Œé›†åˆåˆ¤æ–­æ–‡ä»¶æ˜¯å¦â€œå·²å®Œå…¨ç´¢å¼•â€ã€‚
fn collect_file_statuses(
    root: &str,
    text_exts: &[String],
    exclude_patterns: &[String],
    max_lines_per_blob: usize,
    existing_blob_names: &HashSet<String>,
) -> anyhow::Result<Vec<FileIndexStatus>> {
    let root_path = PathBuf::from(root);
    if !root_path.exists() {
        anyhow::bail!("é¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: {}", root);
    }

    // æ„å»ºæ’é™¤æ¨¡å¼çš„ GlobSet
    let exclude_globset = if exclude_patterns.is_empty() {
        None
    } else {
        match build_exclude_globset(exclude_patterns) {
            Ok(gs) => Some(gs),
            Err(e) => {
                log_debug!("æ„å»ºæ’é™¤æ¨¡å¼å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•åŒ¹é…: {}", e);
                None
            }
        }
    };

    let gitignore = build_gitignore(&root_path);
    let mut dirs_stack = vec![root_path.clone()];
    let mut files_status = Vec::new();

    while let Some(dir) = dirs_stack.pop() {
        let entries = match fs::read_dir(&dir) {
            Ok(e) => e,
            Err(_) => continue,
        };

        for entry in entries.flatten() {
            let p = entry.path();

            // .gitignore è¿‡æ»¤
            if let Some(gi) = &gitignore {
                if gi.matched_path_or_any_parents(&p, p.is_dir()).is_ignore() {
                    continue;
                }
            }

            if p.is_dir() {
                if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                    continue;
                }
                dirs_stack.push(p);
                continue;
            }

            if should_exclude(&p, &root_path, exclude_globset.as_ref()) {
                continue;
            }

            // æ‰©å±•åè¿‡æ»¤
            let ext_ok = p
                .extension()
                .and_then(|s| s.to_str())
                .map(|e| {
                    let dot = format!(".{}", e).to_lowercase();
                    text_exts.iter().any(|te| te.eq_ignore_ascii_case(&dot))
                })
                .unwrap_or(false);

            if !ext_ok {
                continue;
            }

            let rel = p
                .strip_prefix(&root_path)
                .unwrap_or(&p)
                .to_string_lossy()
                .replace('\\', "/");

            // è¯»å–æ–‡ä»¶å†…å®¹å¹¶æ ¹æ®åˆ†å—ç»“æœè®¡ç®— blob å“ˆå¸Œ
            if let Some(content) = read_file_with_encoding(&p) {
                let blobs = split_content(&rel, &content, max_lines_per_blob);
                if blobs.is_empty() {
                    continue;
                }

                let mut all_indexed = true;
                for blob in &blobs {
                    let hash = sha256_hex(&blob.path, &blob.content);
                    if !existing_blob_names.contains(&hash) {
                        all_indexed = false;
                        break;
                    }
                }

                let status = if all_indexed {
                    FileIndexStatusKind::Indexed
                } else {
                    FileIndexStatusKind::Pending
                };

                files_status.push(FileIndexStatus {
                    path: rel.clone(),
                    status,
                });
            } else {
                // æ— æ³•è¯»å–å†…å®¹æ—¶ï¼Œä¿å®ˆåœ°æ ‡è®°ä¸º Pendingï¼Œé¿å…é™é»˜ä¸¢å¤±
                files_status.push(FileIndexStatus {
                    path: rel.clone(),
                    status: FileIndexStatusKind::Pending,
                });
            }
        }
    }

    Ok(files_status)
}

/// åªæ‰§è¡Œç´¢å¼•æ›´æ–°ï¼Œä¸è¿›è¡Œæœç´¢
/// è¿”å›å€¼ï¼šæˆåŠŸä¸Šä¼ çš„ blob åç§°åˆ—è¡¨
pub(crate) async fn update_index(config: &AcemcpConfig, project_root_path: &str) -> anyhow::Result<Vec<String>> {
    let base_url = config.base_url.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® base_url"))?;
    // ä¸¥æ ¼æ ¡éªŒ base_url
    let has_scheme = base_url.starts_with("http://") || base_url.starts_with("https://");
    let has_host = base_url.trim().len() > "https://".len();
    if !has_scheme || !has_host { anyhow::bail!("æ— æ•ˆçš„ base_urlï¼Œè¯·å¡«å†™å®Œæ•´çš„ http(s)://host[:port] æ ¼å¼"); }
    let token = config.token.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® token"))?;
    let batch_size = config.batch_size.unwrap_or(10) as usize;
    let max_lines = config.max_lines_per_blob.unwrap_or(800) as usize;
    let text_exts = config.text_extensions.clone().unwrap_or_default();
    let exclude_patterns = config.exclude_patterns.clone().unwrap_or_default();

    // æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹ç´¢å¼•
    let _ = update_project_status(project_root_path, |status| {
        status.status = IndexStatus::Indexing;
        status.progress = 0;
    });

    // æ—¥å¿—ï¼šåŸºç¡€é…ç½®
    log_important!(info,
        "=== å¼€å§‹ç´¢å¼•ä»£ç åº“ ==="
    );
    log_important!(info,
        "Acemcpé…ç½®: base_url={}, batch_size={}, max_lines_per_blob={}, text_extsæ•°é‡={}, exclude_patternsæ•°é‡={}",
        base_url,
        batch_size,
        max_lines,
        text_exts.len(),
        exclude_patterns.len()
    );
    log_important!(info,
        "é¡¹ç›®è·¯å¾„: {}", project_root_path
    );

    // æ”¶é›† blobï¼ˆæ ¹æ®æ‰©å±•åä¸æ’é™¤è§„åˆ™ï¼Œç®€åŒ–ç‰ˆ .gitignore æ”¯æŒï¼‰
    log_important!(info, "å¼€å§‹æ”¶é›†ä»£ç æ–‡ä»¶...");
    let blobs = collect_blobs(project_root_path, &text_exts, &exclude_patterns, max_lines)?;
    if blobs.is_empty() {
        // æ›´æ–°çŠ¶æ€ï¼šå¤±è´¥
        let _ = update_project_status(project_root_path, |status| {
            status.status = IndexStatus::Failed;
            status.last_error = Some("æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡æœ¬æ–‡ä»¶".to_string());
            status.last_failure_time = Some(chrono::Utc::now());
        });
        anyhow::bail!("æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡æœ¬æ–‡ä»¶");
    }

    // æ›´æ–°çŠ¶æ€ï¼šæ–‡ä»¶æ”¶é›†å®Œæˆ
    let _ = update_project_status(project_root_path, |status| {
        status.total_files = blobs.len();
        status.progress = 20;
    });

    // åŠ è½½ projects.json
    let projects_path = home_projects_file();
    let mut projects: ProjectsFile = if projects_path.exists() {
        let data = fs::read_to_string(&projects_path).unwrap_or_default();
        serde_json::from_str(&data).unwrap_or_default()
    } else { ProjectsFile::default() };

    // ä½¿ç”¨ normalize_project_path å»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€
    let normalized_root = normalize_project_path(
        &PathBuf::from(project_root_path)
            .canonicalize()
            .unwrap_or_else(|_| PathBuf::from(project_root_path))
            .to_string_lossy()
    );
    let existing_blob_names: std::collections::HashSet<String> = projects.0.get(&normalized_root).cloned().unwrap_or_default().into_iter().collect();

    // è®¡ç®—æ‰€æœ‰ blob çš„å“ˆå¸Œå€¼ï¼Œå»ºç«‹å“ˆå¸Œåˆ° blob çš„æ˜ å°„
    let mut blob_hash_map: std::collections::HashMap<String, BlobItem> = std::collections::HashMap::new();
    for blob in &blobs {
        let hash = sha256_hex(&blob.path, &blob.content);
        blob_hash_map.insert(hash.clone(), blob.clone());
    }

    // åˆ†ç¦»å·²å­˜åœ¨å’Œæ–°å¢åŠ çš„ blobï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    let all_blob_hashes: std::collections::HashSet<String> = blob_hash_map.keys().cloned().collect();
    let existing_hashes: std::collections::HashSet<String> = all_blob_hashes.intersection(&existing_blob_names).cloned().collect();
    let new_hashes: std::collections::HashSet<String> = all_blob_hashes.difference(&existing_blob_names).cloned().collect();

    // éœ€è¦ä¸Šä¼ çš„æ–° blob
    let new_blobs: Vec<BlobItem> = new_hashes.iter().filter_map(|h| blob_hash_map.get(h).cloned()).collect();

    log_important!(info,
        "=== ç´¢å¼•ç»Ÿè®¡ ==="
    );
    log_important!(info,
        "æ”¶é›†åˆ°blobsæ€»æ•°: {}, æ—¢æœ‰blobs: {}, æ–°å¢blobs: {}, éœ€è¦ä¸Šä¼ : {}",
        blobs.len(),
        existing_hashes.len(),
        new_hashes.len(),
        new_blobs.len()
    );

    // åˆ›å»º HTTP å®¢æˆ·ç«¯ï¼ˆæ”¯æŒä»£ç†ï¼‰
    let client = create_acemcp_client(config)?;

    // æ‰¹é‡ä¸Šä¼ æ–°å¢ blobs
    let mut uploaded_names: Vec<String> = Vec::new();
    let mut failed_batches: Vec<usize> = Vec::new();
    
    if !new_blobs.is_empty() {
        let total_batches = (new_blobs.len() + batch_size - 1) / batch_size;
        log_important!(info,
            "=== å¼€å§‹æ‰¹é‡ä¸Šä¼ ä»£ç ç´¢å¼• ==="
        );
        log_important!(info,
            "ç›®æ ‡ç«¯ç‚¹: {}/batch-upload, æ€»æ‰¹æ¬¡: {}, æ¯æ‰¹ä¸Šé™: {}, æ€»blobs: {}",
            base_url,
            total_batches,
            batch_size,
            new_blobs.len()
        );

        log_important!(info,
            "=== æ‰¹é‡ä¸Šä¼ ä»£ç ç´¢å¼• ==="
        );

        for i in 0..total_batches {
            let start = i * batch_size;
            let end = usize::min(start + batch_size, new_blobs.len());
            let batch = &new_blobs[start..end];
            let url = format!("{}/batch-upload", base_url);
            
            log_important!(info,
                "ä¸Šä¼ æ‰¹æ¬¡ {}/{}: url={}, blobs={}",
                i + 1,
                total_batches,
                url,
                batch.len()
            );
            
            // è¯¦ç»†è®°å½•æ¯ä¸ª blob çš„ä¿¡æ¯
            for (idx, blob) in batch.iter().enumerate() {
                // æ³¨æ„ï¼šè¿™é‡Œçš„ path å¯èƒ½åŒ…å«é¡¹ç›®ç»“æ„ä¿¡æ¯ï¼Œé»˜è®¤é™çº§åˆ° debugï¼Œé¿å…æ—¥å¿—è†¨èƒ€
                log_debug!(
                    "  æ‰¹æ¬¡ {} - Blob {}/{}: path={}, content_length={}",
                    i + 1,
                    idx + 1,
                    batch.len(),
                    blob.path,
                    blob.content.len()
                );
            }
            
            let payload = serde_json::json!({"blobs": batch});
            // é¿å…å¯¹ payload æ‰§è¡Œ to_stringï¼ˆä¼šåºåˆ—åŒ–å¹¶å¤åˆ¶å¤§é‡ä»£ç å†…å®¹ï¼‰
            // è¿™é‡Œä»…è®°å½•ä¸€ä¸ªè¿‘ä¼¼å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œç”¨äºæ’æŸ¥æ€§èƒ½é—®é¢˜
            let approx_chars: usize = batch.iter()
                .map(|b| b.path.len() + b.content.len())
                .sum();
            log_debug!("æ‰¹æ¬¡è½½è·æ¦‚è¦: blobs={}, approx_chars={}", batch.len(), approx_chars);
            
            match retry_request(|| async {
                let r = client
                    .post(&url)
                    .header(AUTHORIZATION, format!("Bearer {}", token))
                    .header(CONTENT_TYPE, "application/json")
                    .json(&payload)
                    .send()
                    .await?;
                
                let status = r.status();
                log_important!(info, "HTTPå“åº”çŠ¶æ€: {}", status);
                
                if !status.is_success() {
                    let body = r.text().await.unwrap_or_default();
                    anyhow::bail!("HTTP {} {}", status, body);
                }
                
                let v: serde_json::Value = r.json().await?;
                // åªè®°å½•æ‘˜è¦ï¼Œé¿å…æŠŠå“åº”å…¨æ–‡ï¼ˆå¯èƒ½è¾ƒå¤§ï¼‰å†™å…¥æ—¥å¿—
                let keys: Vec<String> = v
                    .as_object()
                    .map(|m| m.keys().cloned().collect())
                    .unwrap_or_default();
                let blob_names_len = v
                    .get("blob_names")
                    .and_then(|x| x.as_array())
                    .map(|arr| arr.len())
                    .unwrap_or(0);
                log_important!(info, "ä¸Šä¼ å“åº”æ‘˜è¦: keys={:?}, blob_names={}", keys, blob_names_len);
                Ok(v)
            }, 3, 1.0).await {
                Ok(value) => {
                    if let Some(arr) = value.get("blob_names").and_then(|v| v.as_array()) {
                        let mut batch_names: Vec<String> = Vec::new();
                        for v in arr { 
                            if let Some(s) = v.as_str() { 
                                batch_names.push(s.to_string()); 
                            }
                        }
                        
                        if batch_names.is_empty() {
                            log_important!(info, "æ‰¹æ¬¡ {} è¿”å›äº†ç©ºçš„blobåç§°åˆ—è¡¨", i + 1);
                            failed_batches.push(i + 1);
                        } else {
                            uploaded_names.extend(batch_names.clone());
                            log_important!(info, "æ‰¹æ¬¡ {} ä¸Šä¼ æˆåŠŸï¼Œè·å¾— {} ä¸ªblobåç§°", i + 1, batch_names.len());
                            // è¯¦ç»†è®°å½•æ¯ä¸ªä¸Šä¼ æˆåŠŸçš„ blob åç§°
                            for (idx, name) in batch_names.iter().enumerate() {
                                // é»˜è®¤é™çº§åˆ° debugï¼Œé¿å…æ—¥å¿—æ–‡ä»¶è¿‡å¤§
                                log_debug!("  æ‰¹æ¬¡ {} - ä¸Šä¼ æˆåŠŸ Blob {}/{}: name={}", i + 1, idx + 1, batch_names.len(), name);
                            }
                        }
                    } else {
                        log_important!(info, "æ‰¹æ¬¡ {} å“åº”ä¸­ç¼ºå°‘blob_nameså­—æ®µ", i + 1);
                        failed_batches.push(i + 1);
                    }
                }
                Err(e) => {
                    log_important!(info, "æ‰¹æ¬¡ {} ä¸Šä¼ å¤±è´¥: {}", i + 1, e);
                    failed_batches.push(i + 1);
                }
            }
        }
        
        // ä¸Šä¼ ç»“æœæ€»ç»“
        log_important!(info,
            "=== ä¸Šä¼ ç»“æœæ€»ç»“ ==="
        );
        if !failed_batches.is_empty() {
            log_important!(info, "ä¸Šä¼ å®Œæˆï¼Œä½†æœ‰å¤±è´¥çš„æ‰¹æ¬¡: {:?}, æˆåŠŸä¸Šä¼ blobs: {}", failed_batches, uploaded_names.len());
        } else {
            log_important!(info, "æ‰€æœ‰æ‰¹æ¬¡ä¸Šä¼ æˆåŠŸï¼Œå…±ä¸Šä¼  {} ä¸ªblobs", uploaded_names.len());
        }
    } else {
        log_important!(info, "æ²¡æœ‰æ–°çš„blobéœ€è¦ä¸Šä¼ ï¼Œä½¿ç”¨å·²æœ‰ç´¢å¼•");
    }

    // åˆå¹¶å¹¶ä¿å­˜ projects.jsonï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    // åªä¿ç•™å½“å‰é¡¹ç›®ä¸­ä»ç„¶å­˜åœ¨çš„ blob çš„å“ˆå¸Œå€¼ï¼ˆè‡ªåŠ¨åˆ é™¤å·²åˆ é™¤çš„ blobï¼‰
    let all_blob_names: Vec<String> = existing_hashes.into_iter().chain(uploaded_names.into_iter()).collect();
    projects.0.insert(normalized_root.clone(), all_blob_names.clone());
    if let Ok(s) = serde_json::to_string_pretty(&projects) { let _ = fs::write(projects_path, s); }

    // ä½¿ç”¨åˆå¹¶åçš„ blob_namesï¼ˆä¸ Python ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
    let blob_names = all_blob_names;
    if blob_names.is_empty() {
        log_important!(info, "ç´¢å¼•åæœªæ‰¾åˆ° blobsï¼Œé¡¹ç›®è·¯å¾„: {}", normalized_root);
        // æ›´æ–°çŠ¶æ€ï¼šå¤±è´¥
        let _ = update_project_status(project_root_path, |status| {
            status.status = IndexStatus::Failed;
            status.last_error = Some("ç´¢å¼•åæœªæ‰¾åˆ° blobs".to_string());
            status.last_failure_time = Some(chrono::Utc::now());
        });
        anyhow::bail!("ç´¢å¼•åæœªæ‰¾åˆ° blobs");
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯é¦–æ¬¡æˆåŠŸç´¢å¼•ï¼ˆç”¨äº ji é›†æˆï¼‰
    let is_first_success = {
        let status = get_project_status(project_root_path);
        status.last_success_time.is_none()
    };

    // æå–æœ€è¿‘å¢é‡ç´¢å¼•çš„æ–‡ä»¶è·¯å¾„ï¼ˆä» new_blobs ä¸­è·å–ï¼Œæœ€å¤š 5 ä¸ªï¼‰
    // è¯´æ˜ï¼šæŒ‰è·¯å¾„æ’åºå¹¶åšæ–‡ä»¶çº§å»é‡ï¼Œä¿è¯å±•ç¤ºç¨³å®šä¸”ä¸å¸¦ chunk åç¼€
    let mut recent_files: Vec<String> = new_blobs
        .iter()
        .map(|b| strip_chunk_suffix(&b.path).to_string())
        .collect();
    recent_files.sort();
    recent_files.dedup();
    recent_files.truncate(5);

    // æ›´æ–°çŠ¶æ€ï¼šç´¢å¼•æˆåŠŸå®Œæˆ
    let _ = update_project_status(project_root_path, |status| {
        status.status = IndexStatus::Synced;
        status.progress = 100;
        status.indexed_files = blobs.len();
        status.pending_files = 0;
        status.last_success_time = Some(chrono::Utc::now());
        status.last_error = None;
        // ä»…åœ¨æœ‰æ–°å¢æ–‡ä»¶æ—¶æ›´æ–°æœ€è¿‘ç´¢å¼•åˆ—è¡¨
        if !recent_files.is_empty() {
            status.recent_indexed_files = recent_files;
        }
    });

    // é¦–æ¬¡æˆåŠŸç´¢å¼•æ—¶ï¼Œå†™å…¥ ji è®°å¿†
    if is_first_success {
        let _ = write_index_memory_to_ji(project_root_path, config);
    }

    log_important!(info, "ç´¢å¼•æ›´æ–°å®Œæˆï¼Œå…± {} ä¸ª blobs", blob_names.len());
    Ok(blob_names)
}

/// å°†ç´¢å¼•é…ç½®ä¿¡æ¯å†™å…¥ jiï¼ˆè®°å¿†ï¼‰å·¥å…·
fn write_index_memory_to_ji(project_root_path: &str, config: &AcemcpConfig) {
    use super::super::memory::MemoryManager;
    use super::super::memory::MemoryCategory;

    // åˆ›å»ºè®°å¿†ç®¡ç†å™¨
    let mut manager = match MemoryManager::new(project_root_path) {
        Ok(m) => m,
        Err(e) => {
            log_debug!("åˆ›å»ºè®°å¿†ç®¡ç†å™¨å¤±è´¥ï¼ˆä¸å½±å“ç´¢å¼•ï¼‰: {}", e);
            return;
        }
    };

    // æ„å»ºè®°å¿†å†…å®¹
    let text_exts = config.text_extensions.clone().unwrap_or_default();
    let exclude_patterns = config.exclude_patterns.clone().unwrap_or_default();
    let batch_size = config.batch_size.unwrap_or(10);
    let max_lines = config.max_lines_per_blob.unwrap_or(800);

    let memory_content = format!(
        "acemcp ä»£ç ç´¢å¼•å·²å¯ç”¨ - é…ç½®æ‘˜è¦: æ–‡ä»¶æ‰©å±•å={:?}, æ’é™¤æ¨¡å¼={:?}, æ‰¹æ¬¡å¤§å°={}, æœ€å¤§è¡Œæ•°/å—={}",
        text_exts, exclude_patterns, batch_size, max_lines
    );

    // å†™å…¥è®°å¿†ï¼ˆadd_memory ç°åœ¨è¿”å› Option<String>ï¼‰
    match manager.add_memory(&memory_content, MemoryCategory::Context) {
        Ok(Some(id)) => {
            log_important!(info, "å·²å°†ç´¢å¼•é…ç½®å†™å…¥ ji è®°å¿†: id={}", id);
        }
        Ok(None) => {
            log_debug!("ç´¢å¼•é…ç½®è®°å¿†å·²å­˜åœ¨ç›¸ä¼¼å†…å®¹ï¼Œæœªé‡å¤æ·»åŠ ");
        }
        Err(e) => {
            log_debug!("å†™å…¥ ji è®°å¿†å¤±è´¥ï¼ˆä¸å½±å“ç´¢å¼•ï¼‰: {}", e);
        }
    }
}

/// åªæ‰§è¡Œæœç´¢ï¼Œä¸è§¦å‘ç´¢å¼•
/// ä½¿ç”¨å·²æœ‰çš„ç´¢å¼•æ•°æ®è¿›è¡Œæœç´¢
async fn search_only(config: &AcemcpConfig, project_root_path: &str, query: &str) -> anyhow::Result<String> {
    let base_url = config.base_url.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® base_url"))?;
    let token = config.token.clone().ok_or_else(|| anyhow::anyhow!("æœªé…ç½® token"))?;

    // ä» projects.json è¯»å–å·²æœ‰çš„ blob åç§°
    let projects_path = home_projects_file();
    let projects: ProjectsFile = if projects_path.exists() {
        let data = fs::read_to_string(&projects_path).unwrap_or_default();
        serde_json::from_str(&data).unwrap_or_default()
    } else {
        ProjectsFile::default()
    };

    // ä½¿ç”¨ normalize_project_path å»é™¤ Windows æ‰©å±•è·¯å¾„å‰ç¼€
    let normalized_root = normalize_project_path(
        &PathBuf::from(project_root_path)
            .canonicalize()
            .unwrap_or_else(|_| PathBuf::from(project_root_path))
            .to_string_lossy()
    );

    let blob_names = projects.0.get(&normalized_root).cloned().unwrap_or_default();

    if blob_names.is_empty() {
        anyhow::bail!("é¡¹ç›®å°šæœªç´¢å¼•æˆ–ç´¢å¼•ä¸ºç©ºï¼Œè¯·å…ˆæ‰§è¡Œç´¢å¼•æ“ä½œ");
    }

    // å‘èµ·æ£€ç´¢
    log_important!(info,
        "=== å¼€å§‹ä»£ç æ£€ç´¢ï¼ˆä»…æœç´¢æ¨¡å¼ï¼‰ ==="
    );
    let search_url = format!("{}/agents/codebase-retrieval", base_url);
    log_important!(info, "æ£€ç´¢è¯·æ±‚: url={}, ä½¿ç”¨blobsæ•°é‡={}, æŸ¥è¯¢å†…å®¹={}", search_url, blob_names.len(), query);

    let payload = serde_json::json!({
        "information_request": query,
        "blobs": {"checkpoint_id": serde_json::Value::Null, "added_blobs": blob_names, "deleted_blobs": []},
        "dialog": [],
        "max_output_length": 0,
        "disable_codebase_retrieval": false,
        "enable_commit_retrieval": false,
    });

    // åˆ›å»º HTTP å®¢æˆ·ç«¯ï¼ˆæ”¯æŒä»£ç†ï¼‰
    let client = create_acemcp_client(config)?;
    let value: serde_json::Value = retry_request(|| async {
        let r = client
            .post(&search_url)
            .header(AUTHORIZATION, format!("Bearer {}", token))
            .header(CONTENT_TYPE, "application/json")
            .json(&payload)
            .send()
            .await?;

        let status = r.status();
        log_important!(info, "æ£€ç´¢è¯·æ±‚HTTPå“åº”çŠ¶æ€: {}", status);

        if !status.is_success() {
            let body = r.text().await.unwrap_or_default();
            anyhow::bail!("HTTP {} {}", status, body);
        }

        let v: serde_json::Value = r.json().await?;
        // åªè®°å½•æ‘˜è¦ï¼Œé¿å…å°† formatted_retrievalï¼ˆå¯èƒ½åŒ…å«å¤§é‡ä»£ç ç‰‡æ®µï¼‰å†™å…¥æ—¥å¿—
        let keys: Vec<String> = v
            .as_object()
            .map(|m| m.keys().cloned().collect())
            .unwrap_or_default();
        let formatted_len = v
            .get("formatted_retrieval")
            .and_then(|x| x.as_str())
            .map(|s| s.len())
            .unwrap_or(0);
        log_important!(info, "æ£€ç´¢å“åº”æ‘˜è¦: keys={:?}, formatted_retrieval_len={}", keys, formatted_len);
        Ok(v)
    }, 3, 2.0).await?;

    let text = value
        .get("formatted_retrieval")
        .and_then(|v| v.as_str())
        .unwrap_or("")
        .to_string();

    if text.is_empty() {
        log_important!(info, "æœç´¢è¿”å›ç©ºç»“æœ");
        Ok("No relevant code context found for your query.".to_string())
    } else {
        log_important!(info, "æœç´¢æˆåŠŸï¼Œè¿”å›æ–‡æœ¬é•¿åº¦: {}", text.len());
        Ok(text)
    }
}

/// åˆ›å»ºæ”¯æŒä»£ç†çš„ HTTP å®¢æˆ·ç«¯
/// æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨ä»£ç†
fn create_acemcp_client(config: &AcemcpConfig) -> anyhow::Result<Client> {
    let mut client_builder = Client::builder()
        .timeout(Duration::from_secs(60));
    
    // æ£€æŸ¥æ˜¯å¦å¯ç”¨ä»£ç†
    if config.proxy_enabled.unwrap_or(false) {
        let host = config.proxy_host.clone().unwrap_or_else(|| "127.0.0.1".to_string());
        let port = config.proxy_port.unwrap_or(7890);
        let proxy_type = config.proxy_type.clone().unwrap_or_else(|| "http".to_string());
        
        // æ ¡éªŒä»£ç†ç±»å‹ï¼Œé¿å…æ‹¼æ¥å‡ºæ— æ•ˆ URL
        match proxy_type.as_str() {
            "http" | "https" | "socks5" => {}
            other => anyhow::bail!("ä¸æ”¯æŒçš„ä»£ç†ç±»å‹: {}ï¼ˆä»…æ”¯æŒ http/https/socks5ï¼‰", other),
        }

        // ä»…ç”¨äºæ—¥å¿—æç¤ºï¼ˆé¿å…æ³„éœ²å¯†ç ï¼‰
        let has_auth = config
            .proxy_username
            .as_deref()
            .map(|u| !u.trim().is_empty())
            .unwrap_or(false);

        if has_auth {
            log_important!(info, "ğŸ”§ ä½¿ç”¨ä»£ç†: {}://{}:{}ï¼ˆå¸¦è®¤è¯ï¼‰", proxy_type, host, port);
        } else {
            log_important!(info, "ğŸ”§ ä½¿ç”¨ä»£ç†: {}://{}:{}", proxy_type, host, port);
        }
        
        // æ„å»ºä»£ç† URL
        let proxy_url = format!("{}://{}:{}", proxy_type, host, port);
        
        // ä½¿ç”¨ Proxy::all() è®©æ‰€æœ‰è¯·æ±‚éƒ½èµ°ä»£ç†
        let mut reqwest_proxy = reqwest::Proxy::all(&proxy_url)
            .map_err(|e| anyhow::anyhow!("åˆ›å»ºä»£ç†å¤±è´¥: {}", e))?;

        // ä»£ç†è®¤è¯ï¼ˆBasic Authï¼‰
        if let Some(username) = config.proxy_username.as_deref() {
            let username = username.trim();
            if !username.is_empty() {
                let password = config.proxy_password.as_deref().unwrap_or("");
                reqwest_proxy = reqwest_proxy.basic_auth(username, password);
            }
        }

        client_builder = client_builder.proxy(reqwest_proxy);
    } else {
        log_debug!("ä½¿ç”¨ç›´è¿æ¨¡å¼ï¼ˆæœªå¯ç”¨ä»£ç†ï¼‰");
    }
    
    client_builder.build()
        .map_err(|e| anyhow::anyhow!("æ„å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e))
}
